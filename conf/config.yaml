%YAML 1.2
---
# Experiment mode: Switch between debug and experiment methods
# mode: fedstdev_centralized
# mode: centralized
mode: fedavg
# mode: fedstdev
# mode: fedgradstd
# mode: debug
desc: 'Fedavg run with CIFAR10 and Two CNN'

defaults:
  - base_config
  - hydra: custom
  - server: baseflower
  # - strategy: base
  # - strategy: fedstdev
  - strategy: fedgradstd
  # - client: fedstdev
  - client: fedgradstd
  # - client: base
  # - client: baseflower
  # - train: base_trainer
  - _self_

simulator:
  # Simulator Mode: Takes arguments 'federated', 'standalone' or 'centralized', 'flower'
  # mode: centralized
  # mode: federated
  mode: flower 
  seed: 42
  use_tensorboard: false
  use_wandb: true
  save_csv: true
  out_prefix: ''
  num_clients: 6
  num_rounds: 200
  checkpoint_every: 10
  eval_type: both
  eval_every: 1
  flwr_resources:
    num_cpus: 3
    num_gpus: 0.5 #TODO: Couple this with device init

train_cfg:
  epochs: 1
  device: auto
  batch_size: 128
  eval_batch_size: 256
  lr: 0.01
  lr_decay: 0.977
  optimizer:
    _target_: torch.optim.SGD
    _partial_: true
    lr: ${train_cfg.lr}
  criterion:
    _target_: torch.nn.CrossEntropyLoss
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.ExponentialLR
    _partial_: true
    gamma: ${train_cfg.lr_decay}
  metric_cfg:
    eval_metrics: ['acc1']
    file_prefix: ''
    log_to_file: false


dataset:
  dataset_family: torchvision
  name: CIFAR10
  data_path: data/
  subsample: false
  subsample_fraction: 1.0 # Fraction of the dataset to use. Only works when subsample is true
  federated: true

  transforms:
    resize:
      _target_: torchvision.transforms.Resize
      size: 
        - 28
        - 28

  split_conf:
    # split_type: one_label_flipped_client
    # split_type: one_imbalanced_client
    split_type: iid
    # split_type: one_noisy_client
    num_splits: ${simulator.num_clients}
    # Noise parameter is specific to one patho client
    # Obsolete now
    # test_fraction: 0.1 # Client train-test split

    noise:
      mu: 0.0
      sigma: 0.5
      flip_percent: 0.5


model:
  name: TwoCNN
  init_type: xavier
  init_gain: 1.0
  dropout: 0.0
  model_spec:           # Optional model spec provided for quick tuning
    _target_: feduciary.models.twocnn.TwoCNN
    _partial_: false
    hidden_size: 200
    # Option to override in_channels and num_classes. Otherwise auto set by the dataset
    in_channels: null
    num_classes: null 


# CONFIG OVERRIDES
# client:
#   train_cfg:
# #     epochs: 1
#     device: auto

# server:
  # _target_: feduciary.server.baseflowerserver.BaseFlowerServer
  # _partial_: true
  # cfg:
  #   eval_every: 1
  #   eval_type: 1
  #   # server_lr: 1.0
  # train_cfg: ${train_cfg}
# ########## OVERRIDES END HERE ##########
# Log Configuration: Additional configurations to be copied in the results summary section. Must be a valid configuration from the config tree.
log_conf: []

...