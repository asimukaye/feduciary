%YAML 1.2
---
mode: cgsv
# mode: debug
desc: "CGSV run with iid data, with sparsify, no delta_normalize"

defaults:
  - base_config
  - hydra: custom
  - server: baseflower

  # - strategy: base
  # - strategy: fedavgmanual
  # - strategy: fedstdev
  # - strategy: fedgradstd
  # - strategy: fedopt
  - strategy: cgsv

  # - client: fedstdev
  # - client: fedgradstd
  - client: baseflower
  - _self_

simulator:
  # Simulator Mode: Takes arguments 'federated', 'standalone' or 'centralized', 'flower'
  # mode: standalone
  # mode: centralized
  mode: federated
  # mode: flower
  seed: 42
  use_tensorboard: false
  use_wandb: true
  save_csv: true
  out_prefix: ''
  num_clients: 6
  num_rounds: 200
  checkpoint_every: 10
  eval_type: both
  eval_every: 1
  flwr_resources:
    num_cpus: 3
    num_gpus: 0.5 #TODO: Couple this with device init

train_cfg:
  epochs: 1
  device: auto
  batch_size: 128
  eval_batch_size: 256
  lr: 0.01
  lr_decay: 0.977
  optimizer:
    _target_: torch.optim.SGD
    _partial_: true
    lr: ${train_cfg.lr}
  criterion:
    _target_: torch.nn.CrossEntropyLoss
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.ExponentialLR
    _partial_: true
    gamma: ${train_cfg.lr_decay}
  metric_cfg:
    eval_metrics: ['acc1']
    file_prefix: ''
    log_to_file: false

dataset:
  dataset_family: torchvision
  # dataset_family: medmnist
  name: CIFAR10
  # name: bloodmnist
  data_path: data/
  subsample: false
  subsample_fraction: 1.0 # Fraction of the dataset to use. Only works when subsample is true
  federated: true

  transforms: null
  #   resize:
  #     _target_: torchvision.transforms.Resize
  #     size: 
  #       - 28
  #       - 28

  split_conf:
    # split_type: n_label_flipped_clients
    # split_type: patho
    # split_type: dirichlet
    # split_type: n_noisy_clients
    # split_type: one_imbalanced_client
    split_type: iid
    # split_type: one_noisy_client
    num_splits: ${simulator.num_clients}
    num_class_per_client: 3 # classes per client for patho split type
    num_patho_clients: 3
    dirichlet_alpha: 1.0
    noise:
      mu: 0.0
      sigma: 0.5
      flip_percent: 0.75

model:
  name: TwoCNN
  init_type: xavier
  init_gain: 1.0
  dropout: 0.0
  model_spec:           # Optional model spec provided for quick tuning
    _target_: feduciary.models.twocnn.TwoCNN
    _partial_: false
    hidden_size: 200
    # Option to override in_channels and num_classes. Otherwise auto set by the dataset
    in_channels: null
    num_classes: null 

# CONFIG OVERRIDES
# client:
#   cfg:
#     data_shuffle: True



# ########## OVERRIDES END HERE ##########
# Log Configuration: Additional configurations to be copied in the results summary section. Must be a valid configuration from the config tree.
# Experiment mode: Switch between debug and experiment methods
# mode: fedstdev_centralized
# mode: centralized
# mode: fedavg_patho
# mode: fedavg_dirichlet
# mode: fedavgmanual
# mode: standalone
# mode: fedstdev
# mode: fedgradstd
# mode: fedgradstd_patho
# mode: fedgradstd_dirichlet
# mode: fedopt_patho
# mode: fedopt
# mode: debug
# mode: cgsv
# desc: 'Centralized run with three label flipped client'
# desc: 'Centralized run with three noisy client'
# desc: 'Fedgradstd client dirichlet split with equal weighting strategy'
# desc: 'Fedgradstd client with equal weighting strategy'
# desc: 'Fedgradstd dry runs for analyzing different metrics with three label flipped clients and 25 % data'
# desc: 'Fedgradstd run with dirichlet split,5 shuffles only'
# desc: 'Fedavg run with bloodmnist iid'
# desc: 'Centralized run with bloodmnist iid'

# desc: Fedopt with patho split
# desc: CGSV run with three label fliped clients
# desc: 'Fedavg run with dirichlet split, alpha 10000, checking dirichlet correctness'
# desc: 'Fedavg manual run with three noisy clients'

# desc: 'Fedavg manual run with three label flipped client'


log_conf: []

...