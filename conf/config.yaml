%YAML 1.2
---
# Make sure mode matches the experiment config for full runs
mode: debug
log_conf: [client.cfg.lr]

defaults:
  - base_config
  - server: cgsv
  - _self_

simulator:
  seed: 42
  use_tensorboard: true
  num_clients: 5
  num_rounds: 60

client:
  _target_: src.client.baseclient.BaseClient
  _partial_: true
  cfg:
    epochs: 5
    device: cuda
    batch_size: 32
    optimizer: SGD
    criterion: CrossEntropyLoss
    lr: 0.01
    lr_decay: 0.977
    lr_scheduler:
      _target_: torch.optim.lr_scheduler.ExponentialLR
      _partial_: true
      gamma: ${client.cfg.lr_decay}

    lr_decay_step: null
    beta: null
    shuffle: false
    eval_metrics: ['acc1']

dataset:
  name: MNIST
  data_path: data/
  test_fraction: 0.2
  split_type: iid
  K: ${simulator.num_clients}
  subsample: 1.0
  transforms:
    resize:
      _target_: torchvision.transforms.Resize
      size: 
        - 28
        - 28

model:
  name: TwoCNN
  init_type: xavier
  init_gain: 1.0
  dropout: 0.0
  model_spec:           # Optional model spec provided for quick tuning
    _target_: src.models.twocnn.TwoCNN
    _partial_: false
    hidden_size: 200
    in_channels: null
    num_classes: null 

hydra:
  job:
    name: ${mode}_${dataset.name}
    chdir: true
    env_set:
      HYDRA_FULL_ERROR: 1
  run:
    dir: outputs/${now:%Y-%m-%d}_${hydra.job.name}/${now:%H-%M-%S}_${hydra.job.override_dirname}
  sweep:
    dir: outputs/${now:%Y-%m-%d}_${hydra.job.name}/${now:%H-%M-%S}
    subdir: ${hydra.job.override_dirname}
  job_logging:
    version: 1
    formatters:
      simple:
        format: '[%(levelname)s] - %(message)s'
      stamped:
        format: '%(asctime)s | %(name)s: [%(levelname)s] - %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: stamped
    root:
      handlers: [console, file]


...