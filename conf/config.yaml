%YAML 1.2
---
# Experiment mode: Switch between debug and experiment methods
# mode: fedstdev_centralized
# mode: base_centralized
# mode: fedstdev
mode: debug
desc: ' Fedstev flower mode rerun'

defaults:
  - base_config
  - hydra: custom
  - server: baseflower
  # - strategy: base
  - strategy: fedstdev

  - client: fedstdev
  # - client: base
  # - client: baseflower
  # - train: base_trainer
  - _self_

simulator:
  seed: 42
  use_tensorboard: false
  use_wandb: true
  save_csv: false
  out_prefix: ''
  num_clients: 5
  num_rounds: 30
  checkpoint_every: 20
  eval_type: both
  eval_every: 1
  # Simulator Mode: Takes arguments 'federated', 'standalone' or 'centralized', 'flower'
  # mode: centralized
  mode: federated
  # mode: flower 
  flwr_resources:
    num_cpus: 2
    num_gpus: 0.2 #TODO: Couple this with device init

train_cfg:
  epochs: 5
  device: auto
  batch_size: 128
  eval_batch_size: 256
  lr: 0.01
  lr_decay: 0.977
  optimizer:
    _target_: torch.optim.SGD
    _partial_: true
    lr: ${train_cfg.lr}
  criterion:
    _target_: torch.nn.CrossEntropyLoss
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.ExponentialLR
    _partial_: true
    gamma: ${train_cfg.lr_decay}
  metric_cfg:
    eval_metrics: ['acc1']
    file_prefix: ''
    log_to_file: false


dataset:
  name: CIFAR10
  data_path: data/
  subsample: false
  subsample_fraction: 1.0
  transforms:
    resize:
      _target_: torchvision.transforms.Resize
      size: 
        - 28
        - 28

  split_conf:
    # split_type: one_label_fli`pped_client
    # split_type: one_imbalanced_client
    split_type: iid
    # split_type: one_noisy_client
    num_splits: ${simulator.num_clients}
    # Noise parameter is specific to one patho client
    test_fraction: 0.2 # Client train-test split

    noise:
      mu: 0.0
      sigma: 0.5
      flip_percent: 1.0


model:
  name: TwoCNN
  init_type: xavier
  init_gain: 1.0
  dropout: 0.0
  model_spec:           # Optional model spec provided for quick tuning
    _target_: src.models.twocnn.TwoCNN
    _partial_: false
    hidden_size: 200
    # Option to override in_channels and num_classes. Otherwise auto set by the dataset
    in_channels: null
    num_classes: null 


# CONFIG OVERRIDES
# client:
#   train_cfg:
# #     epochs: 1
#     device: auto

# server:
  # _target_: src.server.baseflowerserver.BaseFlowerServer
  # _partial_: true
  # cfg:
  #   eval_every: 1
  #   eval_type: 1
  #   # server_lr: 1.0
  # train_cfg: ${train_cfg}
# ########## OVERRIDES END HERE ##########
# Log Configuration: Additional configurations to be copied in the results summary section. Must be a valid configuration from the config tree.
log_conf: []

...